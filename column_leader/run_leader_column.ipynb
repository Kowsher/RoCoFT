{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd48bc06-2c45-4226-b18a-802795f18cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "from torch.utils.data import Dataset\n",
    "import logging\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets  = load_dataset(\"glue\", 'mnli')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0af2d704-b278-45aa-88eb-d442a299e322",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kowsher/miniconda3/envs/LD/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, AutoConfig\n",
    "#from roberta import RobertaForSequenceClassification\n",
    "\n",
    "\n",
    "model_name = \"FacebookAI/roberta-base\"\n",
    "\n",
    "#config.num_labels=2\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7f7b9f8-fb0c-472c-984c-4e7403b0485d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "\n",
    "col_to_delete = ['question1','sentence2']\n",
    "\n",
    "def preprocessing_function(examples):\n",
    "    return tokenizer(examples['premise'], examples['hypothesis'])\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(preprocessing_function, batched=True)\n",
    "\n",
    "\n",
    "# llama_tokenized_datasets = llama_tokenized_datasets.rename_column(\"target\", \"label\")\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "# Data collator for padding a batch of examples to the maximum length seen in the batch\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d3e1e1e-a176-476d-a09b-ffef8c304fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import RobertaForSequenceClassification\n",
    "from transformers.activations import ACT2FN\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_name, num_labels=3).to('cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a49a4e8f-0039-410e-ab82-5dfb55617f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import leader\n",
    "\n",
    "leader.PEFT(model, method='column', rank=1) \n",
    "#targets=['key', 'value', 'dense', 'query'])\n",
    "# method = 'row', 'column', 'random'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20873d5b-6578-4315-a6cd-cdfb5ffffb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "\n",
    "\n",
    "    logits, labels = eval_pred # eval_pred is the tuple of predictions and labels returned by the model\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    precision = metrics.precision_score(labels, predictions, average=\"macro\")\n",
    "    recall = metrics.recall_score(labels, predictions, average=\"macro\")\n",
    "    f1 = metrics.f1_score(labels, predictions, average=\"macro\")\n",
    "    accuracy = metrics.accuracy_score(labels, predictions)\n",
    "    \n",
    "    return {\"precision\": precision, \"recall\": recall, \"f1-score\": f1, 'accuracy': accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e5b54f3-7558-4f8f-bd0d-053e50495741",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kowsher/miniconda3/envs/LD/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "import time\n",
    "from transformers import Trainer, TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='dir',\n",
    "    learning_rate=1e-3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.00,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_total_limit=2,\n",
    "    save_steps=10000000,\n",
    "    logging_steps=500,\n",
    "   \n",
    "    load_best_model_at_end=True,\n",
    "    lr_scheduler_type=\"cosine\",  # You can choose from 'linear', 'cosine', 'cosine_with_restarts', 'polynomial', etc.\n",
    "    warmup_steps=100,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation_matched\"],\n",
    "\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2227cdf-7c5d-4dfd-894b-a2e64ebc0366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49088' max='49088' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49088/49088 1:00:50, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.983800</td>\n",
       "      <td>0.699034</td>\n",
       "      <td>0.720294</td>\n",
       "      <td>0.714175</td>\n",
       "      <td>0.714348</td>\n",
       "      <td>0.713602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.692400</td>\n",
       "      <td>0.577162</td>\n",
       "      <td>0.769779</td>\n",
       "      <td>0.767171</td>\n",
       "      <td>0.767576</td>\n",
       "      <td>0.768925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.644800</td>\n",
       "      <td>0.656043</td>\n",
       "      <td>0.764911</td>\n",
       "      <td>0.751323</td>\n",
       "      <td>0.748333</td>\n",
       "      <td>0.752725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.615500</td>\n",
       "      <td>0.549649</td>\n",
       "      <td>0.789532</td>\n",
       "      <td>0.785461</td>\n",
       "      <td>0.785940</td>\n",
       "      <td>0.785940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.626700</td>\n",
       "      <td>0.522995</td>\n",
       "      <td>0.797641</td>\n",
       "      <td>0.796995</td>\n",
       "      <td>0.796321</td>\n",
       "      <td>0.796842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.590700</td>\n",
       "      <td>0.501483</td>\n",
       "      <td>0.801251</td>\n",
       "      <td>0.801244</td>\n",
       "      <td>0.801206</td>\n",
       "      <td>0.802751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.567600</td>\n",
       "      <td>0.504906</td>\n",
       "      <td>0.808376</td>\n",
       "      <td>0.806871</td>\n",
       "      <td>0.806450</td>\n",
       "      <td>0.809272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.589900</td>\n",
       "      <td>0.491589</td>\n",
       "      <td>0.809712</td>\n",
       "      <td>0.809995</td>\n",
       "      <td>0.809482</td>\n",
       "      <td>0.810494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.558700</td>\n",
       "      <td>0.491165</td>\n",
       "      <td>0.812191</td>\n",
       "      <td>0.804803</td>\n",
       "      <td>0.804415</td>\n",
       "      <td>0.808660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.576700</td>\n",
       "      <td>0.489536</td>\n",
       "      <td>0.812612</td>\n",
       "      <td>0.811651</td>\n",
       "      <td>0.810640</td>\n",
       "      <td>0.811615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.547300</td>\n",
       "      <td>0.490658</td>\n",
       "      <td>0.807541</td>\n",
       "      <td>0.801979</td>\n",
       "      <td>0.802842</td>\n",
       "      <td>0.804585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.540300</td>\n",
       "      <td>0.466847</td>\n",
       "      <td>0.818658</td>\n",
       "      <td>0.816258</td>\n",
       "      <td>0.816672</td>\n",
       "      <td>0.818645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.547000</td>\n",
       "      <td>0.469562</td>\n",
       "      <td>0.818253</td>\n",
       "      <td>0.816640</td>\n",
       "      <td>0.816209</td>\n",
       "      <td>0.818951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.535000</td>\n",
       "      <td>0.484433</td>\n",
       "      <td>0.813551</td>\n",
       "      <td>0.805866</td>\n",
       "      <td>0.804211</td>\n",
       "      <td>0.809373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.529000</td>\n",
       "      <td>0.510243</td>\n",
       "      <td>0.807033</td>\n",
       "      <td>0.802762</td>\n",
       "      <td>0.801082</td>\n",
       "      <td>0.804483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.525300</td>\n",
       "      <td>0.467381</td>\n",
       "      <td>0.822306</td>\n",
       "      <td>0.820611</td>\n",
       "      <td>0.820706</td>\n",
       "      <td>0.820886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.527100</td>\n",
       "      <td>0.453559</td>\n",
       "      <td>0.820580</td>\n",
       "      <td>0.820730</td>\n",
       "      <td>0.820402</td>\n",
       "      <td>0.821803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.541900</td>\n",
       "      <td>0.495637</td>\n",
       "      <td>0.815565</td>\n",
       "      <td>0.813249</td>\n",
       "      <td>0.812181</td>\n",
       "      <td>0.812328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.526400</td>\n",
       "      <td>0.458367</td>\n",
       "      <td>0.825287</td>\n",
       "      <td>0.825072</td>\n",
       "      <td>0.824894</td>\n",
       "      <td>0.825471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.523900</td>\n",
       "      <td>0.461840</td>\n",
       "      <td>0.823617</td>\n",
       "      <td>0.822353</td>\n",
       "      <td>0.821703</td>\n",
       "      <td>0.823739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.515400</td>\n",
       "      <td>0.457515</td>\n",
       "      <td>0.822316</td>\n",
       "      <td>0.820835</td>\n",
       "      <td>0.820296</td>\n",
       "      <td>0.822618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.523100</td>\n",
       "      <td>0.454488</td>\n",
       "      <td>0.828832</td>\n",
       "      <td>0.826080</td>\n",
       "      <td>0.826639</td>\n",
       "      <td>0.827611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.513500</td>\n",
       "      <td>0.453722</td>\n",
       "      <td>0.821179</td>\n",
       "      <td>0.819965</td>\n",
       "      <td>0.819785</td>\n",
       "      <td>0.822211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.510200</td>\n",
       "      <td>0.454711</td>\n",
       "      <td>0.824759</td>\n",
       "      <td>0.823612</td>\n",
       "      <td>0.823004</td>\n",
       "      <td>0.825471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.505700</td>\n",
       "      <td>0.449927</td>\n",
       "      <td>0.830350</td>\n",
       "      <td>0.830645</td>\n",
       "      <td>0.830385</td>\n",
       "      <td>0.831279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.517700</td>\n",
       "      <td>0.443233</td>\n",
       "      <td>0.828056</td>\n",
       "      <td>0.825449</td>\n",
       "      <td>0.826119</td>\n",
       "      <td>0.827305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.489800</td>\n",
       "      <td>0.457751</td>\n",
       "      <td>0.826804</td>\n",
       "      <td>0.826748</td>\n",
       "      <td>0.826197</td>\n",
       "      <td>0.827815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.492700</td>\n",
       "      <td>0.469146</td>\n",
       "      <td>0.824145</td>\n",
       "      <td>0.820291</td>\n",
       "      <td>0.819124</td>\n",
       "      <td>0.818849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.487300</td>\n",
       "      <td>0.444600</td>\n",
       "      <td>0.832201</td>\n",
       "      <td>0.828258</td>\n",
       "      <td>0.828770</td>\n",
       "      <td>0.829547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.519000</td>\n",
       "      <td>0.430592</td>\n",
       "      <td>0.835375</td>\n",
       "      <td>0.833655</td>\n",
       "      <td>0.834118</td>\n",
       "      <td>0.835456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.497600</td>\n",
       "      <td>0.436060</td>\n",
       "      <td>0.828770</td>\n",
       "      <td>0.828941</td>\n",
       "      <td>0.828543</td>\n",
       "      <td>0.829750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.509700</td>\n",
       "      <td>0.441297</td>\n",
       "      <td>0.832811</td>\n",
       "      <td>0.832797</td>\n",
       "      <td>0.832418</td>\n",
       "      <td>0.834030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.502200</td>\n",
       "      <td>0.438770</td>\n",
       "      <td>0.830251</td>\n",
       "      <td>0.830158</td>\n",
       "      <td>0.829572</td>\n",
       "      <td>0.831075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.499600</td>\n",
       "      <td>0.434999</td>\n",
       "      <td>0.833176</td>\n",
       "      <td>0.832909</td>\n",
       "      <td>0.832264</td>\n",
       "      <td>0.833724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.490500</td>\n",
       "      <td>0.452908</td>\n",
       "      <td>0.832490</td>\n",
       "      <td>0.830744</td>\n",
       "      <td>0.830626</td>\n",
       "      <td>0.830565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.512000</td>\n",
       "      <td>0.435630</td>\n",
       "      <td>0.832235</td>\n",
       "      <td>0.831663</td>\n",
       "      <td>0.831382</td>\n",
       "      <td>0.833418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.503600</td>\n",
       "      <td>0.454337</td>\n",
       "      <td>0.828315</td>\n",
       "      <td>0.822671</td>\n",
       "      <td>0.821946</td>\n",
       "      <td>0.825981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.483200</td>\n",
       "      <td>0.430450</td>\n",
       "      <td>0.831746</td>\n",
       "      <td>0.831272</td>\n",
       "      <td>0.831459</td>\n",
       "      <td>0.832501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.492100</td>\n",
       "      <td>0.435349</td>\n",
       "      <td>0.829636</td>\n",
       "      <td>0.829862</td>\n",
       "      <td>0.829276</td>\n",
       "      <td>0.830056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.479600</td>\n",
       "      <td>0.424530</td>\n",
       "      <td>0.836471</td>\n",
       "      <td>0.835780</td>\n",
       "      <td>0.835293</td>\n",
       "      <td>0.837392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>0.489100</td>\n",
       "      <td>0.446759</td>\n",
       "      <td>0.828850</td>\n",
       "      <td>0.827056</td>\n",
       "      <td>0.825898</td>\n",
       "      <td>0.826999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.481600</td>\n",
       "      <td>0.433695</td>\n",
       "      <td>0.833295</td>\n",
       "      <td>0.830582</td>\n",
       "      <td>0.830781</td>\n",
       "      <td>0.833214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>0.487800</td>\n",
       "      <td>0.421806</td>\n",
       "      <td>0.837603</td>\n",
       "      <td>0.837627</td>\n",
       "      <td>0.837494</td>\n",
       "      <td>0.839022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.471100</td>\n",
       "      <td>0.420631</td>\n",
       "      <td>0.838220</td>\n",
       "      <td>0.837870</td>\n",
       "      <td>0.837580</td>\n",
       "      <td>0.839429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>0.484000</td>\n",
       "      <td>0.416458</td>\n",
       "      <td>0.839209</td>\n",
       "      <td>0.839113</td>\n",
       "      <td>0.839157</td>\n",
       "      <td>0.840346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.420110</td>\n",
       "      <td>0.839063</td>\n",
       "      <td>0.839356</td>\n",
       "      <td>0.839069</td>\n",
       "      <td>0.839939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23500</td>\n",
       "      <td>0.475600</td>\n",
       "      <td>0.434061</td>\n",
       "      <td>0.834038</td>\n",
       "      <td>0.833390</td>\n",
       "      <td>0.832535</td>\n",
       "      <td>0.833520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.464300</td>\n",
       "      <td>0.432829</td>\n",
       "      <td>0.837553</td>\n",
       "      <td>0.837523</td>\n",
       "      <td>0.836909</td>\n",
       "      <td>0.837799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24500</td>\n",
       "      <td>0.479700</td>\n",
       "      <td>0.417130</td>\n",
       "      <td>0.843924</td>\n",
       "      <td>0.843797</td>\n",
       "      <td>0.843846</td>\n",
       "      <td>0.844829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.465200</td>\n",
       "      <td>0.441851</td>\n",
       "      <td>0.836126</td>\n",
       "      <td>0.834294</td>\n",
       "      <td>0.833380</td>\n",
       "      <td>0.835354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25500</td>\n",
       "      <td>0.466900</td>\n",
       "      <td>0.417787</td>\n",
       "      <td>0.839088</td>\n",
       "      <td>0.839195</td>\n",
       "      <td>0.838751</td>\n",
       "      <td>0.840245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.457700</td>\n",
       "      <td>0.416657</td>\n",
       "      <td>0.839548</td>\n",
       "      <td>0.839477</td>\n",
       "      <td>0.839058</td>\n",
       "      <td>0.839633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26500</td>\n",
       "      <td>0.464100</td>\n",
       "      <td>0.407599</td>\n",
       "      <td>0.841246</td>\n",
       "      <td>0.840412</td>\n",
       "      <td>0.840213</td>\n",
       "      <td>0.842282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.460800</td>\n",
       "      <td>0.422494</td>\n",
       "      <td>0.841080</td>\n",
       "      <td>0.840947</td>\n",
       "      <td>0.840883</td>\n",
       "      <td>0.841569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27500</td>\n",
       "      <td>0.460500</td>\n",
       "      <td>0.406322</td>\n",
       "      <td>0.845139</td>\n",
       "      <td>0.845018</td>\n",
       "      <td>0.845003</td>\n",
       "      <td>0.845848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.453200</td>\n",
       "      <td>0.421426</td>\n",
       "      <td>0.840650</td>\n",
       "      <td>0.840887</td>\n",
       "      <td>0.840603</td>\n",
       "      <td>0.841569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28500</td>\n",
       "      <td>0.464400</td>\n",
       "      <td>0.428992</td>\n",
       "      <td>0.835180</td>\n",
       "      <td>0.834619</td>\n",
       "      <td>0.833725</td>\n",
       "      <td>0.834743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>0.456900</td>\n",
       "      <td>0.409044</td>\n",
       "      <td>0.841146</td>\n",
       "      <td>0.840581</td>\n",
       "      <td>0.840216</td>\n",
       "      <td>0.842282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29500</td>\n",
       "      <td>0.456500</td>\n",
       "      <td>0.404259</td>\n",
       "      <td>0.842395</td>\n",
       "      <td>0.842289</td>\n",
       "      <td>0.842157</td>\n",
       "      <td>0.843810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.445200</td>\n",
       "      <td>0.420318</td>\n",
       "      <td>0.841940</td>\n",
       "      <td>0.841221</td>\n",
       "      <td>0.840348</td>\n",
       "      <td>0.841773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30500</td>\n",
       "      <td>0.458500</td>\n",
       "      <td>0.407006</td>\n",
       "      <td>0.844951</td>\n",
       "      <td>0.844860</td>\n",
       "      <td>0.844894</td>\n",
       "      <td>0.845848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>0.458700</td>\n",
       "      <td>0.404477</td>\n",
       "      <td>0.846948</td>\n",
       "      <td>0.845939</td>\n",
       "      <td>0.846194</td>\n",
       "      <td>0.847682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31500</td>\n",
       "      <td>0.445200</td>\n",
       "      <td>0.415730</td>\n",
       "      <td>0.843142</td>\n",
       "      <td>0.843321</td>\n",
       "      <td>0.842785</td>\n",
       "      <td>0.843709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.446400</td>\n",
       "      <td>0.409051</td>\n",
       "      <td>0.843998</td>\n",
       "      <td>0.843987</td>\n",
       "      <td>0.843444</td>\n",
       "      <td>0.844829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32500</td>\n",
       "      <td>0.442800</td>\n",
       "      <td>0.401161</td>\n",
       "      <td>0.847411</td>\n",
       "      <td>0.847292</td>\n",
       "      <td>0.847179</td>\n",
       "      <td>0.847784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>0.450900</td>\n",
       "      <td>0.401262</td>\n",
       "      <td>0.845262</td>\n",
       "      <td>0.845043</td>\n",
       "      <td>0.844877</td>\n",
       "      <td>0.846460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33500</td>\n",
       "      <td>0.458300</td>\n",
       "      <td>0.397664</td>\n",
       "      <td>0.844972</td>\n",
       "      <td>0.844313</td>\n",
       "      <td>0.844123</td>\n",
       "      <td>0.845950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.461900</td>\n",
       "      <td>0.398154</td>\n",
       "      <td>0.846141</td>\n",
       "      <td>0.846433</td>\n",
       "      <td>0.846127</td>\n",
       "      <td>0.847275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34500</td>\n",
       "      <td>0.447400</td>\n",
       "      <td>0.405173</td>\n",
       "      <td>0.845810</td>\n",
       "      <td>0.845985</td>\n",
       "      <td>0.845504</td>\n",
       "      <td>0.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>0.435800</td>\n",
       "      <td>0.400571</td>\n",
       "      <td>0.847359</td>\n",
       "      <td>0.846840</td>\n",
       "      <td>0.846599</td>\n",
       "      <td>0.848497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35500</td>\n",
       "      <td>0.441800</td>\n",
       "      <td>0.397277</td>\n",
       "      <td>0.846061</td>\n",
       "      <td>0.846182</td>\n",
       "      <td>0.845865</td>\n",
       "      <td>0.847275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.435600</td>\n",
       "      <td>0.398370</td>\n",
       "      <td>0.846900</td>\n",
       "      <td>0.846879</td>\n",
       "      <td>0.846889</td>\n",
       "      <td>0.847988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36500</td>\n",
       "      <td>0.444000</td>\n",
       "      <td>0.401040</td>\n",
       "      <td>0.846564</td>\n",
       "      <td>0.846687</td>\n",
       "      <td>0.846600</td>\n",
       "      <td>0.847784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37000</td>\n",
       "      <td>0.435600</td>\n",
       "      <td>0.402436</td>\n",
       "      <td>0.848873</td>\n",
       "      <td>0.848665</td>\n",
       "      <td>0.848535</td>\n",
       "      <td>0.849007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37500</td>\n",
       "      <td>0.431500</td>\n",
       "      <td>0.396667</td>\n",
       "      <td>0.850089</td>\n",
       "      <td>0.849804</td>\n",
       "      <td>0.849911</td>\n",
       "      <td>0.850739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>0.442600</td>\n",
       "      <td>0.389356</td>\n",
       "      <td>0.849106</td>\n",
       "      <td>0.849160</td>\n",
       "      <td>0.849105</td>\n",
       "      <td>0.850331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38500</td>\n",
       "      <td>0.433900</td>\n",
       "      <td>0.397050</td>\n",
       "      <td>0.848331</td>\n",
       "      <td>0.848160</td>\n",
       "      <td>0.848044</td>\n",
       "      <td>0.849618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39000</td>\n",
       "      <td>0.445900</td>\n",
       "      <td>0.396334</td>\n",
       "      <td>0.848290</td>\n",
       "      <td>0.848434</td>\n",
       "      <td>0.848352</td>\n",
       "      <td>0.849312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39500</td>\n",
       "      <td>0.435500</td>\n",
       "      <td>0.392117</td>\n",
       "      <td>0.849739</td>\n",
       "      <td>0.850013</td>\n",
       "      <td>0.849830</td>\n",
       "      <td>0.850841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.438000</td>\n",
       "      <td>0.392230</td>\n",
       "      <td>0.850087</td>\n",
       "      <td>0.850356</td>\n",
       "      <td>0.850165</td>\n",
       "      <td>0.851248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40500</td>\n",
       "      <td>0.432500</td>\n",
       "      <td>0.396924</td>\n",
       "      <td>0.848825</td>\n",
       "      <td>0.849190</td>\n",
       "      <td>0.848787</td>\n",
       "      <td>0.849720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41000</td>\n",
       "      <td>0.423500</td>\n",
       "      <td>0.395715</td>\n",
       "      <td>0.848868</td>\n",
       "      <td>0.848492</td>\n",
       "      <td>0.848397</td>\n",
       "      <td>0.850025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41500</td>\n",
       "      <td>0.428800</td>\n",
       "      <td>0.396639</td>\n",
       "      <td>0.850341</td>\n",
       "      <td>0.850648</td>\n",
       "      <td>0.850411</td>\n",
       "      <td>0.851452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>0.428200</td>\n",
       "      <td>0.395533</td>\n",
       "      <td>0.849092</td>\n",
       "      <td>0.849388</td>\n",
       "      <td>0.849012</td>\n",
       "      <td>0.850229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42500</td>\n",
       "      <td>0.435600</td>\n",
       "      <td>0.395341</td>\n",
       "      <td>0.850049</td>\n",
       "      <td>0.850386</td>\n",
       "      <td>0.850047</td>\n",
       "      <td>0.851146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43000</td>\n",
       "      <td>0.421700</td>\n",
       "      <td>0.393957</td>\n",
       "      <td>0.851827</td>\n",
       "      <td>0.851789</td>\n",
       "      <td>0.851777</td>\n",
       "      <td>0.852573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43500</td>\n",
       "      <td>0.441700</td>\n",
       "      <td>0.392872</td>\n",
       "      <td>0.849999</td>\n",
       "      <td>0.850238</td>\n",
       "      <td>0.849934</td>\n",
       "      <td>0.851248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>0.414500</td>\n",
       "      <td>0.392835</td>\n",
       "      <td>0.850591</td>\n",
       "      <td>0.850878</td>\n",
       "      <td>0.850671</td>\n",
       "      <td>0.851758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44500</td>\n",
       "      <td>0.441500</td>\n",
       "      <td>0.390694</td>\n",
       "      <td>0.850663</td>\n",
       "      <td>0.850901</td>\n",
       "      <td>0.850733</td>\n",
       "      <td>0.851859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>0.436500</td>\n",
       "      <td>0.391615</td>\n",
       "      <td>0.850422</td>\n",
       "      <td>0.850742</td>\n",
       "      <td>0.850480</td>\n",
       "      <td>0.851554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45500</td>\n",
       "      <td>0.428900</td>\n",
       "      <td>0.390615</td>\n",
       "      <td>0.851427</td>\n",
       "      <td>0.851715</td>\n",
       "      <td>0.851508</td>\n",
       "      <td>0.852573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46000</td>\n",
       "      <td>0.427600</td>\n",
       "      <td>0.390651</td>\n",
       "      <td>0.850705</td>\n",
       "      <td>0.850980</td>\n",
       "      <td>0.850787</td>\n",
       "      <td>0.851859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46500</td>\n",
       "      <td>0.433000</td>\n",
       "      <td>0.391875</td>\n",
       "      <td>0.851252</td>\n",
       "      <td>0.851542</td>\n",
       "      <td>0.851332</td>\n",
       "      <td>0.852267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47000</td>\n",
       "      <td>0.416700</td>\n",
       "      <td>0.391929</td>\n",
       "      <td>0.850478</td>\n",
       "      <td>0.850765</td>\n",
       "      <td>0.850548</td>\n",
       "      <td>0.851656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47500</td>\n",
       "      <td>0.432700</td>\n",
       "      <td>0.391538</td>\n",
       "      <td>0.851183</td>\n",
       "      <td>0.851454</td>\n",
       "      <td>0.851275</td>\n",
       "      <td>0.852267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48000</td>\n",
       "      <td>0.440400</td>\n",
       "      <td>0.391280</td>\n",
       "      <td>0.851656</td>\n",
       "      <td>0.851880</td>\n",
       "      <td>0.851740</td>\n",
       "      <td>0.852674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48500</td>\n",
       "      <td>0.427200</td>\n",
       "      <td>0.391226</td>\n",
       "      <td>0.851656</td>\n",
       "      <td>0.851880</td>\n",
       "      <td>0.851740</td>\n",
       "      <td>0.852674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49000</td>\n",
       "      <td>0.427100</td>\n",
       "      <td>0.391237</td>\n",
       "      <td>0.851548</td>\n",
       "      <td>0.851774</td>\n",
       "      <td>0.851632</td>\n",
       "      <td>0.852573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=49088, training_loss=0.4878309172477374, metrics={'train_runtime': 3650.3506, 'train_samples_per_second': 215.159, 'train_steps_per_second': 13.447, 'total_flos': 78459613178400.0, 'train_loss': 0.4878309172477374, 'epoch': 2.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1fce1c-a9c0-440d-9265-2ca9ec88a029",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
