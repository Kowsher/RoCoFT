{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd48bc06-2c45-4226-b18a-802795f18cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "from torch.utils.data import Dataset\n",
    "import logging\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets  = load_dataset(\"glue\", 'mnli')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0af2d704-b278-45aa-88eb-d442a299e322",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kowsher/miniconda3/envs/LD/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, AutoConfig\n",
    "#from roberta import RobertaForSequenceClassification\n",
    "\n",
    "\n",
    "model_name = \"FacebookAI/roberta-base\"\n",
    "\n",
    "#config.num_labels=2\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7f7b9f8-fb0c-472c-984c-4e7403b0485d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "\n",
    "col_to_delete = ['question1','sentence2']\n",
    "\n",
    "def preprocessing_function(examples):\n",
    "    return tokenizer(examples['premise'], examples['hypothesis'])\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(preprocessing_function, batched=True)\n",
    "\n",
    "\n",
    "# llama_tokenized_datasets = llama_tokenized_datasets.rename_column(\"target\", \"label\")\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "# Data collator for padding a batch of examples to the maximum length seen in the batch\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d3e1e1e-a176-476d-a09b-ffef8c304fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import RobertaForSequenceClassification\n",
    "from transformers.activations import ACT2FN\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_name, num_labels=3).to('cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a49a4e8f-0039-410e-ab82-5dfb55617f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import leader\n",
    "\n",
    "leader.PEFT(model, method='row', rank=1) \n",
    "#targets=['key', 'value', 'dense', 'query'])\n",
    "# method = 'row', 'column', 'random'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20873d5b-6578-4315-a6cd-cdfb5ffffb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "\n",
    "\n",
    "    logits, labels = eval_pred # eval_pred is the tuple of predictions and labels returned by the model\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    precision = metrics.precision_score(labels, predictions, average=\"macro\")\n",
    "    recall = metrics.recall_score(labels, predictions, average=\"macro\")\n",
    "    f1 = metrics.f1_score(labels, predictions, average=\"macro\")\n",
    "    accuracy = metrics.accuracy_score(labels, predictions)\n",
    "    \n",
    "    return {\"precision\": precision, \"recall\": recall, \"f1-score\": f1, 'accuracy': accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e5b54f3-7558-4f8f-bd0d-053e50495741",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kowsher/miniconda3/envs/LD/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "import time\n",
    "from transformers import Trainer, TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='dir',\n",
    "    learning_rate=1e-3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.00,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_total_limit=2,\n",
    "    save_steps=10000000,\n",
    "    logging_steps=500,\n",
    "   \n",
    "    load_best_model_at_end=True,\n",
    "    lr_scheduler_type=\"cosine\",  # You can choose from 'linear', 'cosine', 'cosine_with_restarts', 'polynomial', etc.\n",
    "    warmup_steps=100,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation_matched\"],\n",
    "\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2227cdf-7c5d-4dfd-894b-a2e64ebc0366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49088' max='49088' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49088/49088 1:52:31, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.986300</td>\n",
       "      <td>0.687132</td>\n",
       "      <td>0.713911</td>\n",
       "      <td>0.710619</td>\n",
       "      <td>0.706414</td>\n",
       "      <td>0.715945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.688600</td>\n",
       "      <td>0.577329</td>\n",
       "      <td>0.771204</td>\n",
       "      <td>0.771214</td>\n",
       "      <td>0.770548</td>\n",
       "      <td>0.773306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.643400</td>\n",
       "      <td>0.573040</td>\n",
       "      <td>0.787978</td>\n",
       "      <td>0.780347</td>\n",
       "      <td>0.778464</td>\n",
       "      <td>0.781966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.603400</td>\n",
       "      <td>0.538006</td>\n",
       "      <td>0.796326</td>\n",
       "      <td>0.791620</td>\n",
       "      <td>0.791980</td>\n",
       "      <td>0.791849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.621100</td>\n",
       "      <td>0.522976</td>\n",
       "      <td>0.799480</td>\n",
       "      <td>0.798931</td>\n",
       "      <td>0.798275</td>\n",
       "      <td>0.799796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.590900</td>\n",
       "      <td>0.502850</td>\n",
       "      <td>0.802824</td>\n",
       "      <td>0.802790</td>\n",
       "      <td>0.802532</td>\n",
       "      <td>0.803260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.568800</td>\n",
       "      <td>0.500445</td>\n",
       "      <td>0.806177</td>\n",
       "      <td>0.805223</td>\n",
       "      <td>0.804751</td>\n",
       "      <td>0.807132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.577500</td>\n",
       "      <td>0.510036</td>\n",
       "      <td>0.804543</td>\n",
       "      <td>0.803003</td>\n",
       "      <td>0.802052</td>\n",
       "      <td>0.803464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.556300</td>\n",
       "      <td>0.481201</td>\n",
       "      <td>0.812804</td>\n",
       "      <td>0.810233</td>\n",
       "      <td>0.809550</td>\n",
       "      <td>0.812634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.565900</td>\n",
       "      <td>0.565345</td>\n",
       "      <td>0.799655</td>\n",
       "      <td>0.793763</td>\n",
       "      <td>0.791983</td>\n",
       "      <td>0.792868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.539000</td>\n",
       "      <td>0.479075</td>\n",
       "      <td>0.813518</td>\n",
       "      <td>0.808262</td>\n",
       "      <td>0.809005</td>\n",
       "      <td>0.811309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.535800</td>\n",
       "      <td>0.463911</td>\n",
       "      <td>0.816920</td>\n",
       "      <td>0.815208</td>\n",
       "      <td>0.815242</td>\n",
       "      <td>0.817626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.549700</td>\n",
       "      <td>0.466760</td>\n",
       "      <td>0.816220</td>\n",
       "      <td>0.815618</td>\n",
       "      <td>0.814999</td>\n",
       "      <td>0.817117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.527000</td>\n",
       "      <td>0.472993</td>\n",
       "      <td>0.816806</td>\n",
       "      <td>0.815891</td>\n",
       "      <td>0.815123</td>\n",
       "      <td>0.817422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.526300</td>\n",
       "      <td>0.521010</td>\n",
       "      <td>0.813648</td>\n",
       "      <td>0.808028</td>\n",
       "      <td>0.806579</td>\n",
       "      <td>0.809781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.519600</td>\n",
       "      <td>0.494493</td>\n",
       "      <td>0.818528</td>\n",
       "      <td>0.813314</td>\n",
       "      <td>0.812901</td>\n",
       "      <td>0.812124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.521200</td>\n",
       "      <td>0.462848</td>\n",
       "      <td>0.820679</td>\n",
       "      <td>0.820552</td>\n",
       "      <td>0.820128</td>\n",
       "      <td>0.821905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.537600</td>\n",
       "      <td>0.461581</td>\n",
       "      <td>0.824639</td>\n",
       "      <td>0.823667</td>\n",
       "      <td>0.823644</td>\n",
       "      <td>0.823943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.534000</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.825057</td>\n",
       "      <td>0.824106</td>\n",
       "      <td>0.823773</td>\n",
       "      <td>0.826083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.526600</td>\n",
       "      <td>0.455509</td>\n",
       "      <td>0.829927</td>\n",
       "      <td>0.830143</td>\n",
       "      <td>0.829987</td>\n",
       "      <td>0.831075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.519400</td>\n",
       "      <td>0.456874</td>\n",
       "      <td>0.823606</td>\n",
       "      <td>0.821631</td>\n",
       "      <td>0.820939</td>\n",
       "      <td>0.823739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.525400</td>\n",
       "      <td>0.455871</td>\n",
       "      <td>0.829078</td>\n",
       "      <td>0.826966</td>\n",
       "      <td>0.827333</td>\n",
       "      <td>0.828120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.513500</td>\n",
       "      <td>0.455995</td>\n",
       "      <td>0.821066</td>\n",
       "      <td>0.821096</td>\n",
       "      <td>0.821066</td>\n",
       "      <td>0.822211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.507800</td>\n",
       "      <td>0.476066</td>\n",
       "      <td>0.822275</td>\n",
       "      <td>0.821106</td>\n",
       "      <td>0.820091</td>\n",
       "      <td>0.822109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.508700</td>\n",
       "      <td>0.476794</td>\n",
       "      <td>0.823204</td>\n",
       "      <td>0.823178</td>\n",
       "      <td>0.822604</td>\n",
       "      <td>0.823841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.522200</td>\n",
       "      <td>0.436394</td>\n",
       "      <td>0.835188</td>\n",
       "      <td>0.834242</td>\n",
       "      <td>0.834537</td>\n",
       "      <td>0.835558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.491400</td>\n",
       "      <td>0.471749</td>\n",
       "      <td>0.822641</td>\n",
       "      <td>0.822718</td>\n",
       "      <td>0.822162</td>\n",
       "      <td>0.823637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.500500</td>\n",
       "      <td>0.456593</td>\n",
       "      <td>0.831974</td>\n",
       "      <td>0.829812</td>\n",
       "      <td>0.829225</td>\n",
       "      <td>0.829139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.486100</td>\n",
       "      <td>0.450895</td>\n",
       "      <td>0.828882</td>\n",
       "      <td>0.823299</td>\n",
       "      <td>0.823815</td>\n",
       "      <td>0.824758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.512800</td>\n",
       "      <td>0.437479</td>\n",
       "      <td>0.835942</td>\n",
       "      <td>0.833666</td>\n",
       "      <td>0.834011</td>\n",
       "      <td>0.834539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.501100</td>\n",
       "      <td>0.446100</td>\n",
       "      <td>0.831328</td>\n",
       "      <td>0.831311</td>\n",
       "      <td>0.830750</td>\n",
       "      <td>0.832094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.513100</td>\n",
       "      <td>0.445571</td>\n",
       "      <td>0.831145</td>\n",
       "      <td>0.831347</td>\n",
       "      <td>0.830911</td>\n",
       "      <td>0.832196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.499500</td>\n",
       "      <td>0.446911</td>\n",
       "      <td>0.828634</td>\n",
       "      <td>0.828631</td>\n",
       "      <td>0.828140</td>\n",
       "      <td>0.828732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.495800</td>\n",
       "      <td>0.436644</td>\n",
       "      <td>0.831511</td>\n",
       "      <td>0.831661</td>\n",
       "      <td>0.831116</td>\n",
       "      <td>0.832196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.493000</td>\n",
       "      <td>0.496155</td>\n",
       "      <td>0.829287</td>\n",
       "      <td>0.822449</td>\n",
       "      <td>0.821920</td>\n",
       "      <td>0.820886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.514400</td>\n",
       "      <td>0.446791</td>\n",
       "      <td>0.829646</td>\n",
       "      <td>0.827303</td>\n",
       "      <td>0.826577</td>\n",
       "      <td>0.829547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.499200</td>\n",
       "      <td>0.436832</td>\n",
       "      <td>0.835885</td>\n",
       "      <td>0.833684</td>\n",
       "      <td>0.833525</td>\n",
       "      <td>0.836169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.477700</td>\n",
       "      <td>0.433197</td>\n",
       "      <td>0.834285</td>\n",
       "      <td>0.833722</td>\n",
       "      <td>0.833911</td>\n",
       "      <td>0.835252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.490100</td>\n",
       "      <td>0.441746</td>\n",
       "      <td>0.833116</td>\n",
       "      <td>0.833306</td>\n",
       "      <td>0.832750</td>\n",
       "      <td>0.833622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.481100</td>\n",
       "      <td>0.452705</td>\n",
       "      <td>0.833480</td>\n",
       "      <td>0.831457</td>\n",
       "      <td>0.830641</td>\n",
       "      <td>0.833214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>0.490800</td>\n",
       "      <td>0.471860</td>\n",
       "      <td>0.824940</td>\n",
       "      <td>0.821746</td>\n",
       "      <td>0.820338</td>\n",
       "      <td>0.820683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.482300</td>\n",
       "      <td>0.435104</td>\n",
       "      <td>0.832740</td>\n",
       "      <td>0.831087</td>\n",
       "      <td>0.831260</td>\n",
       "      <td>0.833418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>0.489500</td>\n",
       "      <td>0.436879</td>\n",
       "      <td>0.835007</td>\n",
       "      <td>0.834259</td>\n",
       "      <td>0.833707</td>\n",
       "      <td>0.835456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.469400</td>\n",
       "      <td>0.434804</td>\n",
       "      <td>0.839215</td>\n",
       "      <td>0.839067</td>\n",
       "      <td>0.838509</td>\n",
       "      <td>0.839735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>0.485700</td>\n",
       "      <td>0.421754</td>\n",
       "      <td>0.840235</td>\n",
       "      <td>0.840127</td>\n",
       "      <td>0.840173</td>\n",
       "      <td>0.841263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.482000</td>\n",
       "      <td>0.434998</td>\n",
       "      <td>0.836548</td>\n",
       "      <td>0.836567</td>\n",
       "      <td>0.836374</td>\n",
       "      <td>0.837799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23500</td>\n",
       "      <td>0.470700</td>\n",
       "      <td>0.452374</td>\n",
       "      <td>0.838616</td>\n",
       "      <td>0.838259</td>\n",
       "      <td>0.837475</td>\n",
       "      <td>0.838003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.467200</td>\n",
       "      <td>0.440604</td>\n",
       "      <td>0.837757</td>\n",
       "      <td>0.837871</td>\n",
       "      <td>0.837363</td>\n",
       "      <td>0.838207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24500</td>\n",
       "      <td>0.483200</td>\n",
       "      <td>0.432571</td>\n",
       "      <td>0.841799</td>\n",
       "      <td>0.841695</td>\n",
       "      <td>0.841529</td>\n",
       "      <td>0.842078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.464800</td>\n",
       "      <td>0.455028</td>\n",
       "      <td>0.836227</td>\n",
       "      <td>0.833639</td>\n",
       "      <td>0.832656</td>\n",
       "      <td>0.834845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25500</td>\n",
       "      <td>0.469300</td>\n",
       "      <td>0.410723</td>\n",
       "      <td>0.840315</td>\n",
       "      <td>0.840513</td>\n",
       "      <td>0.840388</td>\n",
       "      <td>0.841467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.452600</td>\n",
       "      <td>0.431703</td>\n",
       "      <td>0.839047</td>\n",
       "      <td>0.838836</td>\n",
       "      <td>0.838267</td>\n",
       "      <td>0.838716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26500</td>\n",
       "      <td>0.460500</td>\n",
       "      <td>0.420780</td>\n",
       "      <td>0.839700</td>\n",
       "      <td>0.838818</td>\n",
       "      <td>0.838611</td>\n",
       "      <td>0.840754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.458800</td>\n",
       "      <td>0.438999</td>\n",
       "      <td>0.838385</td>\n",
       "      <td>0.838344</td>\n",
       "      <td>0.837724</td>\n",
       "      <td>0.838411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27500</td>\n",
       "      <td>0.463800</td>\n",
       "      <td>0.416251</td>\n",
       "      <td>0.843679</td>\n",
       "      <td>0.843713</td>\n",
       "      <td>0.843683</td>\n",
       "      <td>0.844829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.454700</td>\n",
       "      <td>0.424614</td>\n",
       "      <td>0.841029</td>\n",
       "      <td>0.840962</td>\n",
       "      <td>0.840960</td>\n",
       "      <td>0.842282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28500</td>\n",
       "      <td>0.457000</td>\n",
       "      <td>0.431771</td>\n",
       "      <td>0.838854</td>\n",
       "      <td>0.838149</td>\n",
       "      <td>0.837312</td>\n",
       "      <td>0.838512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>0.458600</td>\n",
       "      <td>0.421049</td>\n",
       "      <td>0.841745</td>\n",
       "      <td>0.841579</td>\n",
       "      <td>0.841094</td>\n",
       "      <td>0.842690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29500</td>\n",
       "      <td>0.455800</td>\n",
       "      <td>0.402676</td>\n",
       "      <td>0.843844</td>\n",
       "      <td>0.843265</td>\n",
       "      <td>0.843424</td>\n",
       "      <td>0.844829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.440500</td>\n",
       "      <td>0.427049</td>\n",
       "      <td>0.841098</td>\n",
       "      <td>0.840947</td>\n",
       "      <td>0.840290</td>\n",
       "      <td>0.841467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30500</td>\n",
       "      <td>0.452000</td>\n",
       "      <td>0.420295</td>\n",
       "      <td>0.845590</td>\n",
       "      <td>0.844587</td>\n",
       "      <td>0.844761</td>\n",
       "      <td>0.845237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>0.450300</td>\n",
       "      <td>0.408696</td>\n",
       "      <td>0.845819</td>\n",
       "      <td>0.845200</td>\n",
       "      <td>0.845376</td>\n",
       "      <td>0.846765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31500</td>\n",
       "      <td>0.442300</td>\n",
       "      <td>0.413967</td>\n",
       "      <td>0.843194</td>\n",
       "      <td>0.843517</td>\n",
       "      <td>0.843168</td>\n",
       "      <td>0.844218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.451500</td>\n",
       "      <td>0.411344</td>\n",
       "      <td>0.846145</td>\n",
       "      <td>0.846440</td>\n",
       "      <td>0.846056</td>\n",
       "      <td>0.847173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32500</td>\n",
       "      <td>0.439700</td>\n",
       "      <td>0.402912</td>\n",
       "      <td>0.847271</td>\n",
       "      <td>0.846959</td>\n",
       "      <td>0.846869</td>\n",
       "      <td>0.847376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>0.452700</td>\n",
       "      <td>0.407029</td>\n",
       "      <td>0.846577</td>\n",
       "      <td>0.846666</td>\n",
       "      <td>0.846548</td>\n",
       "      <td>0.847784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33500</td>\n",
       "      <td>0.450600</td>\n",
       "      <td>0.407823</td>\n",
       "      <td>0.844511</td>\n",
       "      <td>0.843672</td>\n",
       "      <td>0.843220</td>\n",
       "      <td>0.845135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.458400</td>\n",
       "      <td>0.413890</td>\n",
       "      <td>0.844405</td>\n",
       "      <td>0.844384</td>\n",
       "      <td>0.844035</td>\n",
       "      <td>0.844524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34500</td>\n",
       "      <td>0.441600</td>\n",
       "      <td>0.410799</td>\n",
       "      <td>0.848233</td>\n",
       "      <td>0.848319</td>\n",
       "      <td>0.847847</td>\n",
       "      <td>0.848293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>0.436900</td>\n",
       "      <td>0.414185</td>\n",
       "      <td>0.845900</td>\n",
       "      <td>0.846070</td>\n",
       "      <td>0.845701</td>\n",
       "      <td>0.846969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35500</td>\n",
       "      <td>0.437900</td>\n",
       "      <td>0.407859</td>\n",
       "      <td>0.843376</td>\n",
       "      <td>0.843377</td>\n",
       "      <td>0.842917</td>\n",
       "      <td>0.844320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.431400</td>\n",
       "      <td>0.408916</td>\n",
       "      <td>0.845281</td>\n",
       "      <td>0.845591</td>\n",
       "      <td>0.845338</td>\n",
       "      <td>0.846358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36500</td>\n",
       "      <td>0.442400</td>\n",
       "      <td>0.407592</td>\n",
       "      <td>0.847485</td>\n",
       "      <td>0.847739</td>\n",
       "      <td>0.847485</td>\n",
       "      <td>0.848701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37000</td>\n",
       "      <td>0.431500</td>\n",
       "      <td>0.409227</td>\n",
       "      <td>0.850219</td>\n",
       "      <td>0.849418</td>\n",
       "      <td>0.849255</td>\n",
       "      <td>0.849516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37500</td>\n",
       "      <td>0.426500</td>\n",
       "      <td>0.403898</td>\n",
       "      <td>0.848257</td>\n",
       "      <td>0.847943</td>\n",
       "      <td>0.848018</td>\n",
       "      <td>0.848701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>0.441200</td>\n",
       "      <td>0.397596</td>\n",
       "      <td>0.847568</td>\n",
       "      <td>0.847726</td>\n",
       "      <td>0.847512</td>\n",
       "      <td>0.848803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38500</td>\n",
       "      <td>0.439600</td>\n",
       "      <td>0.403218</td>\n",
       "      <td>0.848457</td>\n",
       "      <td>0.848139</td>\n",
       "      <td>0.848004</td>\n",
       "      <td>0.849618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39000</td>\n",
       "      <td>0.439800</td>\n",
       "      <td>0.401055</td>\n",
       "      <td>0.848489</td>\n",
       "      <td>0.848650</td>\n",
       "      <td>0.848556</td>\n",
       "      <td>0.849516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39500</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.402759</td>\n",
       "      <td>0.847643</td>\n",
       "      <td>0.847890</td>\n",
       "      <td>0.847628</td>\n",
       "      <td>0.848395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>0.402258</td>\n",
       "      <td>0.849492</td>\n",
       "      <td>0.849846</td>\n",
       "      <td>0.849555</td>\n",
       "      <td>0.850433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40500</td>\n",
       "      <td>0.434600</td>\n",
       "      <td>0.403216</td>\n",
       "      <td>0.847339</td>\n",
       "      <td>0.847660</td>\n",
       "      <td>0.847248</td>\n",
       "      <td>0.848090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41000</td>\n",
       "      <td>0.422100</td>\n",
       "      <td>0.400731</td>\n",
       "      <td>0.847452</td>\n",
       "      <td>0.847090</td>\n",
       "      <td>0.846981</td>\n",
       "      <td>0.848599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41500</td>\n",
       "      <td>0.427600</td>\n",
       "      <td>0.403855</td>\n",
       "      <td>0.848445</td>\n",
       "      <td>0.848787</td>\n",
       "      <td>0.848492</td>\n",
       "      <td>0.849414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>0.423500</td>\n",
       "      <td>0.403949</td>\n",
       "      <td>0.846453</td>\n",
       "      <td>0.846752</td>\n",
       "      <td>0.846364</td>\n",
       "      <td>0.847478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42500</td>\n",
       "      <td>0.431300</td>\n",
       "      <td>0.404163</td>\n",
       "      <td>0.845966</td>\n",
       "      <td>0.846273</td>\n",
       "      <td>0.845840</td>\n",
       "      <td>0.846867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43000</td>\n",
       "      <td>0.419000</td>\n",
       "      <td>0.404463</td>\n",
       "      <td>0.850259</td>\n",
       "      <td>0.850329</td>\n",
       "      <td>0.850223</td>\n",
       "      <td>0.850942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43500</td>\n",
       "      <td>0.438200</td>\n",
       "      <td>0.401546</td>\n",
       "      <td>0.847462</td>\n",
       "      <td>0.847697</td>\n",
       "      <td>0.847359</td>\n",
       "      <td>0.848599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>0.419300</td>\n",
       "      <td>0.400355</td>\n",
       "      <td>0.848294</td>\n",
       "      <td>0.848616</td>\n",
       "      <td>0.848353</td>\n",
       "      <td>0.849312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44500</td>\n",
       "      <td>0.441400</td>\n",
       "      <td>0.395737</td>\n",
       "      <td>0.848566</td>\n",
       "      <td>0.848861</td>\n",
       "      <td>0.848626</td>\n",
       "      <td>0.849720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>0.433800</td>\n",
       "      <td>0.397786</td>\n",
       "      <td>0.847447</td>\n",
       "      <td>0.847762</td>\n",
       "      <td>0.847438</td>\n",
       "      <td>0.848497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45500</td>\n",
       "      <td>0.421800</td>\n",
       "      <td>0.397981</td>\n",
       "      <td>0.848023</td>\n",
       "      <td>0.848346</td>\n",
       "      <td>0.848056</td>\n",
       "      <td>0.849109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46000</td>\n",
       "      <td>0.427700</td>\n",
       "      <td>0.397991</td>\n",
       "      <td>0.847914</td>\n",
       "      <td>0.848239</td>\n",
       "      <td>0.847951</td>\n",
       "      <td>0.849007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46500</td>\n",
       "      <td>0.429700</td>\n",
       "      <td>0.399818</td>\n",
       "      <td>0.847967</td>\n",
       "      <td>0.848305</td>\n",
       "      <td>0.847989</td>\n",
       "      <td>0.848905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47000</td>\n",
       "      <td>0.414400</td>\n",
       "      <td>0.398953</td>\n",
       "      <td>0.848503</td>\n",
       "      <td>0.848808</td>\n",
       "      <td>0.848528</td>\n",
       "      <td>0.849618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47500</td>\n",
       "      <td>0.427800</td>\n",
       "      <td>0.398837</td>\n",
       "      <td>0.848690</td>\n",
       "      <td>0.849015</td>\n",
       "      <td>0.848753</td>\n",
       "      <td>0.849720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48000</td>\n",
       "      <td>0.435400</td>\n",
       "      <td>0.398630</td>\n",
       "      <td>0.849260</td>\n",
       "      <td>0.849585</td>\n",
       "      <td>0.849323</td>\n",
       "      <td>0.850229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48500</td>\n",
       "      <td>0.426100</td>\n",
       "      <td>0.398584</td>\n",
       "      <td>0.849363</td>\n",
       "      <td>0.849684</td>\n",
       "      <td>0.849427</td>\n",
       "      <td>0.850331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49000</td>\n",
       "      <td>0.427500</td>\n",
       "      <td>0.398564</td>\n",
       "      <td>0.849363</td>\n",
       "      <td>0.849684</td>\n",
       "      <td>0.849427</td>\n",
       "      <td>0.850331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=49088, training_loss=0.48622018432990205, metrics={'train_runtime': 6751.7577, 'train_samples_per_second': 116.326, 'train_steps_per_second': 7.27, 'total_flos': 78751220835600.0, 'train_loss': 0.48622018432990205, 'epoch': 2.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f212cb8-1e78-4101-bf03-bc2a62d976c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
